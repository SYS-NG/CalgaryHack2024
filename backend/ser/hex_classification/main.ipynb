{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n",
      "/opt/homebrew/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import librosa\n",
    "import numpy as np\n",
    "from pydub import AudioSegment, effects\n",
    "import noisereduce as nr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load first model\n",
    "saved_model_path = './six_model.json'\n",
    "saved_weights_path = './six_model_weights.h5'\n",
    "\n",
    "# Load new, better model\n",
    "# saved_model_path = './goodmodel.json'\n",
    "# saved_weights_path = './goodmodel_weights.h5'\n",
    "\n",
    "with open(saved_model_path , 'r') as json_file:\n",
    "    json_savedModel = json_file.read()\n",
    "\n",
    "model = tf.keras.models.model_from_json(json_savedModel)  # Assuming json_savedModel is defined\n",
    "model.load_weights(saved_weights_path)\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "                optimizer='RMSProp', \n",
    "                metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import librosa\n",
    "import numpy as np\n",
    "from pydub import AudioSegment, effects\n",
    "import noisereduce as nr\n",
    "\n",
    "total_length = 173056 # desired frame length for all of the audio samples.\n",
    "def preprocess(file_path, frame_length = 2048, hop_length = 512):\n",
    "    '''\n",
    "    A process to an audio .wav file before execcuting a prediction.\n",
    "      Arguments:\n",
    "      - file_path - The system path to the audio file.\n",
    "      - frame_length - Length of the frame over which to compute the speech features. default: 2048\n",
    "      - hop_length - Number of samples to advance for each frame. default: 512\n",
    "\n",
    "      Return:\n",
    "        'X_3D' variable, containing a shape of: (batch, timesteps, feature) for a single file (batch = 1).\n",
    "    ''' \n",
    "    # Fetch sample rate.\n",
    "    _, sr = librosa.load(path = file_path, sr = None)\n",
    "    # Load audio file\n",
    "    rawsound = AudioSegment.from_file(file_path, duration = None) \n",
    "    # Normalize to 5 dBFS \n",
    "    normalizedsound = effects.normalize(rawsound, headroom = 5.0) \n",
    "    # Transform the normalized audio to np.array of samples.\n",
    "    normal_x = np.array(normalizedsound.get_array_of_samples(), dtype = 'float32')\n",
    "# Trim silence from the beginning and the end.\n",
    "    xt, index = librosa.effects.trim(normal_x, top_db=30)\n",
    "    try:\n",
    "        padded_x = np.pad(xt, (0, total_length-len(xt)), 'constant')\n",
    "    except:\n",
    "        print(\"error\")\n",
    "        print(\"file:\", file)\n",
    "        return None\n",
    "    # normal_x = np.array(normalizedsound.get_array_of_samples(), dtype = 'float32') \n",
    "    # Noise reduction                  \n",
    "    final_x = nr.reduce_noise(padded_x, sr=sr)\n",
    "        \n",
    "        \n",
    "    f1 = librosa.feature.rms(y=final_x, frame_length=frame_length, hop_length=hop_length, center=True, pad_mode='reflect').T # Energy - Root Mean Square\n",
    "    f2 = librosa.feature.zero_crossing_rate(y=final_x, frame_length=frame_length, hop_length=hop_length,center=True).T # ZCR\n",
    "    f3 = librosa.feature.mfcc(y=final_x, sr=sr, S=None, n_mfcc=13, hop_length = hop_length).T # MFCC   \n",
    "    X = np.concatenate((f2, f1, f3), axis = 1)\n",
    "    \n",
    "    X_3D = np.expand_dims(X, axis=0)\n",
    "    \n",
    "    return X_3D\n",
    "\n",
    "# file_path = './test_files/copy_OAF_fail_disgust.wav'  # Update with the path to your .wav file\n",
    "# file_path = './own_recordings/rec12.wav'\n",
    "file_path = '../final_test/steven_happy_2.wav'\n",
    "\n",
    "preprocessed_file = preprocess(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 327ms/step\n",
      "---------\n",
      "File: ../final_test/luke_long_1.wav\n",
      "[[0.0011203  0.00100184 0.02389973 0.05518602 0.06875975 0.8500323 ]]\n",
      "5\n",
      "Predicted emotion: fearful\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(preprocessed_file)\n",
    "np.set_printoptions(suppress=True)\n",
    "print(\"---------\")\n",
    "print(\"File:\", file_path)\n",
    "print(predictions)\n",
    "\n",
    "# Assuming your model outputs a softmax distribution over emotions\n",
    "emotions = ['neutral', 'calm', 'happy', 'sad', 'angry', 'fearful']  \n",
    "print(np.argmax(predictions))\n",
    "predicted_emotion = emotions[np.argmax(predictions)]\n",
    "print(f\"Predicted emotion: {predicted_emotion}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workflow for processing multiple files at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error\n",
      "file: luke_long_1.wav\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "---------\n",
      "File: luke_sad_2.wav\n",
      "neutral  calm     happy    sad      angry    fearful \n",
      "0.001    0.005    0.016    0.706    0.006    0.267   \n",
      "3\n",
      "Predicted emotion: sad\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "---------\n",
      "File: luke_happy_1.wav\n",
      "neutral  calm     happy    sad      angry    fearful \n",
      "0.001    0.0      0.005    0.987    0.0      0.007   \n",
      "3\n",
      "Predicted emotion: sad\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "---------\n",
      "File: luke_sad_1.wav\n",
      "neutral  calm     happy    sad      angry    fearful \n",
      "0.0      0.001    0.009    0.245    0.015    0.73    \n",
      "5\n",
      "Predicted emotion: fearful\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "---------\n",
      "File: luke_happy_2.wav\n",
      "neutral  calm     happy    sad      angry    fearful \n",
      "0.003    0.0      0.0      0.997    0.0      0.0     \n",
      "3\n",
      "Predicted emotion: sad\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "---------\n",
      "File: steven_neutral_1.wav\n",
      "neutral  calm     happy    sad      angry    fearful \n",
      "0.0      0.001    0.091    0.015    0.071    0.823   \n",
      "5\n",
      "Predicted emotion: fearful\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "---------\n",
      "File: luke_angry_1.wav\n",
      "neutral  calm     happy    sad      angry    fearful \n",
      "0.001    0.0      0.0      0.998    0.001    0.0     \n",
      "3\n",
      "Predicted emotion: sad\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "---------\n",
      "File: steven_neutral_2.wav\n",
      "neutral  calm     happy    sad      angry    fearful \n",
      "0.011    0.001    0.03     0.733    0.077    0.148   \n",
      "3\n",
      "Predicted emotion: sad\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "---------\n",
      "File: luke_angry_2.wav\n",
      "neutral  calm     happy    sad      angry    fearful \n",
      "0.001    0.0      0.0      0.995    0.003    0.0     \n",
      "3\n",
      "Predicted emotion: sad\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "---------\n",
      "File: steven_angry_1.wav\n",
      "neutral  calm     happy    sad      angry    fearful \n",
      "0.003    0.0      0.001    0.994    0.002    0.0     \n",
      "3\n",
      "Predicted emotion: sad\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "---------\n",
      "File: steven_angry_2.wav\n",
      "neutral  calm     happy    sad      angry    fearful \n",
      "0.006    0.0      0.0      0.993    0.001    0.0     \n",
      "3\n",
      "Predicted emotion: sad\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "---------\n",
      "File: steven_happy_1.wav\n",
      "neutral  calm     happy    sad      angry    fearful \n",
      "0.002    0.0      0.003    0.992    0.0      0.002   \n",
      "3\n",
      "Predicted emotion: sad\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "---------\n",
      "File: luke_disgusted_1.wav\n",
      "neutral  calm     happy    sad      angry    fearful \n",
      "0.035    0.001    0.089    0.866    0.008    0.001   \n",
      "3\n",
      "Predicted emotion: sad\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "---------\n",
      "File: steven_disgusted_2.wav\n",
      "neutral  calm     happy    sad      angry    fearful \n",
      "0.0      0.0      0.153    0.018    0.82     0.008   \n",
      "4\n",
      "Predicted emotion: angry\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "---------\n",
      "File: steven_happy_2.wav\n",
      "neutral  calm     happy    sad      angry    fearful \n",
      "0.001    0.001    0.024    0.055    0.069    0.85    \n",
      "5\n",
      "Predicted emotion: fearful\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "---------\n",
      "File: luke_disgusted_2.wav\n",
      "neutral  calm     happy    sad      angry    fearful \n",
      "0.0      0.0      0.025    0.262    0.688    0.025   \n",
      "4\n",
      "Predicted emotion: angry\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "---------\n",
      "File: steven_disgusted_1.wav\n",
      "neutral  calm     happy    sad      angry    fearful \n",
      "0.002    0.0      0.045    0.722    0.229    0.002   \n",
      "3\n",
      "Predicted emotion: sad\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "---------\n",
      "File: luke_neutral_1.wav\n",
      "neutral  calm     happy    sad      angry    fearful \n",
      "0.0      0.0      0.998    0.0      0.001    0.001   \n",
      "2\n",
      "Predicted emotion: happy\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "---------\n",
      "File: steven_sad_2.wav\n",
      "neutral  calm     happy    sad      angry    fearful \n",
      "0.0      0.001    0.016    0.389    0.002    0.592   \n",
      "5\n",
      "Predicted emotion: fearful\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "---------\n",
      "File: luke_neutral_2.wav\n",
      "neutral  calm     happy    sad      angry    fearful \n",
      "0.0      0.0      0.022    0.592    0.02     0.365   \n",
      "3\n",
      "Predicted emotion: sad\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "---------\n",
      "File: steven_sad_1.wav\n",
      "neutral  calm     happy    sad      angry    fearful \n",
      "0.001    0.001    0.004    0.448    0.003    0.544   \n",
      "5\n",
      "Predicted emotion: fearful\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "preprocessed_files = []\n",
    "preprocessed_files_names = []\n",
    "directory = '../final_test'\n",
    "for file in os.listdir(directory):\n",
    "    if '.DS_Store' in file:\n",
    "      continue\n",
    "    file_path = os.path.join(directory, file)\n",
    "    processed_file = preprocess(file_path)\n",
    "    if processed_file is not None:\n",
    "        preprocessed_files.append(processed_file)\n",
    "        preprocessed_files_names.append(file)\n",
    "\n",
    "for i, f in enumerate(preprocessed_files):\n",
    "    emotions = ['neutral', 'calm', 'happy', 'sad', 'angry', 'fearful']  \n",
    "\n",
    "    predictions = model.predict(f)\n",
    "    rounded_predictions = np.round(predictions[0], 3)\n",
    "    # predictions_list = rounded_predictions.tolist()\n",
    "    # print(predictions_list)\n",
    "    np.set_printoptions(suppress=True)\n",
    "    print(\"---------\")\n",
    "    print(\"File:\", preprocessed_files_names[i])\n",
    "    print(' '.join(f'{col:<8}' for col in emotions))\n",
    "    print(' '.join(f'{str(val):<8}' for val in rounded_predictions))\n",
    "\n",
    "    # Assuming your model outputs a softmax distribution over emotions\n",
    " \n",
    "    print(np.argmax(predictions))\n",
    "    predicted_emotion = emotions[np.argmax(predictions)]\n",
    "    print(f\"Predicted emotion: {predicted_emotion}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of longer audio files by breaking them down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "No librosa attribute output",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/lukeson/Coding/Hackathons/CalgaryHack2024/backend/ser/main.ipynb Cell 10\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lukeson/Coding/Hackathons/CalgaryHack2024/backend/ser/main.ipynb#X13sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m     plt\u001b[39m.\u001b[39mshow()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lukeson/Coding/Hackathons/CalgaryHack2024/backend/ser/main.ipynb#X13sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m \u001b[39m# Call the function to process the audio file\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/lukeson/Coding/Hackathons/CalgaryHack2024/backend/ser/main.ipynb#X13sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m process_audio_file(FILE_PATH)\n",
      "\u001b[1;32m/Users/lukeson/Coding/Hackathons/CalgaryHack2024/backend/ser/main.ipynb Cell 10\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lukeson/Coding/Hackathons/CalgaryHack2024/backend/ser/main.ipynb#X13sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39m# Save chunk to temporary WAV file or directly pass the audio array to your preprocessing function if possible\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lukeson/Coding/Hackathons/CalgaryHack2024/backend/ser/main.ipynb#X13sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m chunk_file_path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtemp_chunk.wav\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/lukeson/Coding/Hackathons/CalgaryHack2024/backend/ser/main.ipynb#X13sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m librosa\u001b[39m.\u001b[39;49moutput\u001b[39m.\u001b[39mwrite_wav(chunk_file_path, chunk, sr)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lukeson/Coding/Hackathons/CalgaryHack2024/backend/ser/main.ipynb#X13sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39m# Preprocess the chunk\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lukeson/Coding/Hackathons/CalgaryHack2024/backend/ser/main.ipynb#X13sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m x \u001b[39m=\u001b[39m preprocess(chunk_file_path)  \u001b[39m# Ensure your preprocess function is adapted for handling the chunk\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/lazy_loader/__init__.py:89\u001b[0m, in \u001b[0;36mattach.<locals>.__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[39mreturn\u001b[39;00m attr\n\u001b[1;32m     88\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 89\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNo \u001b[39m\u001b[39m{\u001b[39;00mpackage_name\u001b[39m}\u001b[39;00m\u001b[39m attribute \u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: No librosa attribute output"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Variables\n",
    "FILE_PATH = './final_test/luke_long_1.wav'\n",
    "SAMPLE_RATE = 24414  # Same as RATE in the original script\n",
    "CHUNK_DURATION = 1  # Duration of chunks to analyze (in seconds)\n",
    "\n",
    "# Function to split audio file into 1-second chunks and process each chunk\n",
    "def process_audio_file(file_path):\n",
    "    total_predictions = []  # List to store predictions for each chunk\n",
    "    \n",
    "    # Load audio file\n",
    "    audio, sr = librosa.load(file_path, sr=SAMPLE_RATE)\n",
    "    \n",
    "    # Calculate the number of chunks\n",
    "    num_chunks = int(np.floor(len(audio) / sr / CHUNK_DURATION))\n",
    "    \n",
    "    for i in range(num_chunks):\n",
    "        # Extract the chunk\n",
    "        start_sample = i * sr * CHUNK_DURATION\n",
    "        end_sample = start_sample + sr * CHUNK_DURATION\n",
    "        chunk = audio[start_sample:end_sample]\n",
    "        \n",
    "        # Save chunk to temporary WAV file or directly pass the audio array to your preprocessing function if possible\n",
    "        chunk_file_path = 'temp_chunk.wav'\n",
    "        librosa.output.write_wav(chunk_file_path, chunk, sr)\n",
    "        \n",
    "        # Preprocess the chunk\n",
    "        x = preprocess(chunk_file_path)  # Ensure your preprocess function is adapted for handling the chunk\n",
    "        \n",
    "        # Model's prediction => an 8 emotion probabilities array\n",
    "        predictions = model.predict(x, use_multiprocessing=True)\n",
    "        pred_list = list(predictions)\n",
    "        pred_np = np.squeeze(np.array(pred_list).tolist(), axis=0)  # Simplify the predictions list\n",
    "        total_predictions.append(pred_np)\n",
    "        \n",
    "        # Optionally, visualize the prediction for each chunk\n",
    "        # emo_list should be defined as your list of emotions\n",
    "        fig = plt.figure(figsize=(10, 2))\n",
    "        plt.bar(emo_list, pred_np, color='darkturquoise')\n",
    "        plt.ylabel(\"Probability (%)\")\n",
    "        plt.show()\n",
    "        \n",
    "        # Print the predominant emotion for the chunk\n",
    "        max_emo = np.argmax(predictions)\n",
    "        print('max emotion for chunk:', emotions.get(max_emo, -1))\n",
    "        print(100 * '-')\n",
    "    \n",
    "    # After processing all chunks, you can aggregate the predictions if needed\n",
    "    # For example, calculate the mean prediction across all chunks\n",
    "    mean_predictions = np.mean(np.array(total_predictions), axis=0)\n",
    "    fig = plt.figure(figsize=(10, 5))\n",
    "    plt.bar(emo_list, mean_predictions, color='indigo')\n",
    "    plt.ylabel(\"Mean probability (%)\")\n",
    "    plt.title(\"Overall Emotion Distribution\")\n",
    "    plt.show()\n",
    "\n",
    "# Call the function to process the audio file\n",
    "process_audio_file(FILE_PATH)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
